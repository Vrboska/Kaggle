{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## First of all I loaded all the data into Snowflake database for easier manipulation\nI made a simple datamart with snap dates '2020-09-01', '2020-09-08' for training\nand '2020-09-15' for testing, datamart was exported in one csv file named\nmodel_build_base.csv\n\n#### The train set contains following data:\n* 495,774 rows of SOLD=1 -> All transactions that were sold in week '2020-09-01' to '2020-09-07' and week '2020-09-08' to '2020-09-15'\n* 4,000,000 randomly chosen combinations of customer_id and article_id that were not sold with SOLD=0\n* All article information, customer information and customer transaction history info is also joined\n\n#### The test set contains following data:\n* Similar to train set just shifted forward for week between '2020-09-15' and '2020-09-22'\n\n\n\n#### Fitting\nA simple XGBoost model was fitted\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-06T13:01:16.795595Z","iopub.execute_input":"2022-11-06T13:01:16.797345Z","iopub.status.idle":"2022-11-06T13:01:16.804791Z","shell.execute_reply.started":"2022-11-06T13:01:16.797256Z","shell.execute_reply":"2022-11-06T13:01:16.803171Z"}}},{"cell_type":"code","source":"#importing custom library\n!pip install git+https://github.com/Vrboska/mofr@master","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport mofr\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (mean_absolute_error,mean_squared_error, mean_squared_log_error)\nfrom xgboost import XGBClassifier, plot_tree\nimport math\n\nimport xgboost as xgb\nimport hyperopt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=1234","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/hm-model-build-base/model_build_base.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #removing bads due to capacity issues (at the end we train with full data though)\n# remove_n = 3000000\n# drop_indices = np.random.choice(df[df['SOLD']==0].index, remove_n, replace=False)\n# df = df.drop(drop_indices)\n#len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns=[\"SOLD\",\"SNAP_DATE\",\"CUSTOMER_ID\",\"ARTICLE_ID\",\"ACTIVE\",\"CLUB_MEMBER_STATUS\",\"FASHION_NEWS_FREQUENCY\",\"AGE\",\"QUANT_PG_ACCESSORIES_1M\",\"QUANT_PG_BAGS_1M\",\"QUANT_PG_COSMETIC_1M\",\"QUANT_PG_FUN_1M\",\"QUANT_PG_FURNITURE_1M\",\"QUANT_PG_GFB_1M\",\"QUANT_PG_GUB_1M\",\"QUANT_PG_GLB_1M\",\"QUANT_PG_GSC_1M\",\"QUANT_PG_IT_1M\",\"QUANT_PG_ITEMS_1M\",\"QUANT_PG_NIGHTWEAR_1M\",\"QUANT_PG_SHOES_1M\",\"QUANT_PG_ST_1M\",\"QUANT_PG_STATIONERY_1M\",\"QUANT_PG_SWIMWEAR_1M\",\"QUANT_PG_UNDERWEAR_1M\",\"QUANT_PG_UNDERWEARNIGHTWEAR_1M\",\"QUANT_PG_UNKNOWN_1M\",\"QUANT_PG_ACCESSORIES_12M\",\"QUANT_PG_BAGS_12M\",\"QUANT_PG_COSMETIC_12M\",\"QUANT_PG_FUN_12M\",\"QUANT_PG_FURNITURE_12M\",\"QUANT_PG_GFB_12M\",\"QUANT_PG_GUB_12M\",\"QUANT_PG_GLB_12M\",\"QUANT_PG_GSC_12M\",\"QUANT_PG_IT_12M\",\"QUANT_PG_ITEMS_12M\",\"QUANT_PG_NIGHTWEAR_12M\",\"QUANT_PG_SHOES_12M\",\"QUANT_PG_ST_12M\",\"QUANT_PG_STATIONERY_12M\",\"QUANT_PG_SWIMWEAR_12M\",\"QUANT_PG_UNDERWEAR_12M\",\"QUANT_PG_UNDERWEARNIGHTWEAR_12M\",\"QUANT_PG_UNKNOWN_12M\",\"QUANT_BLACK_1M\",\"QUANT_WHITE_1M\",\"QUANT_GREY_1M\",\"QUANT_BLUE_1M\",\"QUANT_PINK_1M\",\"QUANT_PURPLE_1M\",\"QUANT_RED_1M\",\"QUANT_ORANGE_1M\",\"QUANT_BROWN_1M\",\"QUANT_YELLOW_1M\",\"QUANT_GREEN_1M\",\"QUANT_BLACK_12M\",\"QUANT_WHITE_12M\",\"QUANT_GREY_12M\",\"QUANT_BLUE_12M\",\"QUANT_PINK_12M\",\"QUANT_PURPLE_12M\",\"QUANT_RED_12M\",\"QUANT_ORANGE_12M\",\"QUANT_BROWN_12M\",\"QUANT_YELLOW_12M\",\"QUANT_GREEN_12M\",\"QUANT_INDEX_BABYCHILDREN_1M\",\"QUANT_INDEX_DIVIDED_1M\",\"QUANT_INDEX_LADIESWEAR_1M\",\"QUANT_INDEX_MENSWEAR_1M\",\"QUANT_INDEX_SPORT_1M\",\"QUANT_INDEX_BABYCHILDREN_12M\",\"QUANT_INDEX_DIVIDED_12M\",\"QUANT_INDEX_LADIESWEAR_12M\",\"QUANT_INDEX_MENSWEAR_12M\",\"QUANT_INDEX_SPORT_12M\",\"ART_PRODUCT_GROUP_NAME\",\"COLOUR\",\"ART_PERCEIVED_COLOUR\",\"ART_INDEX_CODE\",\"ART_INDEX_GROUP_NO\",\"ART_GARMENT_GROUP_NO\",\"ART_QUANTITY_SOLD_1M\",\"ART_QUANTITY_SOLD_3M\",\"ART_QUANTITY_SOLD_12M\",\"ART_QUANTITY_SOLD_OVERALL\",\"ART_DAYS_SINCE_FIRST_PURCHASE\",\"ART_DAYS_SINCE_LAST_PURCHASE\",\"ART_AVERAGE_PRICE\",\"ART_NUM_CHANNEL_2\",\"CUSTART_QUANTITY_SOLD_1M\",\"CUSTART_QUANTITY_SOLD_3M\",\"CUSTART_QUANTITY_SOLD_12M\",\"CUSTART_QUANTITY_SOLD_OVERALL\",\"CUSTART_DAYS_SINCE_FIRST_PURCHASE\",\"CUSTART_DAYS_SINCE_LAST_PURCHASE\",\"CUSTART_NUM_CHANNEL_2\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del df['Unnamed: 0']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['CLUB_MEMBER_STATUS']=df['CLUB_MEMBER_STATUS'].replace(0, np.nan)\n# df['FASHION_NEWS_FREQUENCY']=df['FASHION_NEWS_FREQUENCY'].replace(0, np.nan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_mask=(df['SNAP_DATE']=='2020-09-08')|(df['SNAP_DATE']=='2020-09-01')\nvalid_mask=df['SNAP_DATE']=='2020-09-15'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[train_mask]['SOLD'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[valid_mask]['SOLD'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:00:13.387735Z","iopub.execute_input":"2022-11-06T11:00:13.388366Z","iopub.status.idle":"2022-11-06T11:00:13.395479Z","shell.execute_reply.started":"2022-11-06T11:00:13.388315Z","shell.execute_reply":"2022-11-06T11:00:13.393782Z"}}},{"cell_type":"code","source":"df[train_mask].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[train_mask].describe(include=['O'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data transformations","metadata":{}},{"cell_type":"code","source":"col_target='SOLD'\ncol_exclude=[\n'SNAP_DATE',\n'CUSTOMER_ID',\n'ARTICLE_ID',\n'ART_DAYS_SINCE_FIRST_PURCHASE',\n\ncol_target,\n    \n\n]+[col for col in df.columns if 'CUSTART' in col]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_exclude","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical transformations","metadata":{}},{"cell_type":"code","source":"import category_encoders as ce","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# potential predictors without encoding\ncat_preds = [col for col in df.select_dtypes(include=\"object\") if col not in col_exclude]\nbool_preds = [col for col in df.select_dtypes(include=\"bool\") if col not in col_exclude]\ndatetime_preds = [col for col in df.select_dtypes(include=\"datetime\") if col not in col_exclude]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target Encoding","metadata":{"execution":{"iopub.status.busy":"2022-11-06T11:18:50.992838Z","iopub.execute_input":"2022-11-06T11:18:50.993263Z","iopub.status.idle":"2022-11-06T11:18:51.002318Z","shell.execute_reply.started":"2022-11-06T11:18:50.993229Z","shell.execute_reply":"2022-11-06T11:18:51.000747Z"}}},{"cell_type":"code","source":"# # bayesian target encoding\nencoder = ce.TargetEncoder(min_samples_leaf=1, smoothing=1.0)\nencoder.fit_transform(df[train_mask][cat_preds], df[train_mask][col_target])\n\ndf = pd.concat([df, encoder.transform(df[cat_preds]).add_prefix(\"BAYES_\")], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col_preds=[col for col in df.select_dtypes(include=[\"int\",\"float\"]) if col not in col_exclude]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(col_preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fitting models","metadata":{}},{"cell_type":"code","source":"(df[train_mask][col_target]>0).value_counts(normalize=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost model","metadata":{}},{"cell_type":"markdown","source":"## Fitting model","metadata":{}},{"cell_type":"code","source":"xgb_model = XGBClassifier(max_depth=4, seed=seed, colsample_bytree=1, gamma=1, min_child_weight=5, n_estimators=100)\nxgb_model.fit(df[train_mask].loc[:, col_preds], df[train_mask][col_target], verbose=0, eval_metric='logloss')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['XGB_SCORE']=xgb_model.predict_proba(df[col_preds])[:, 1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The Lift on the train set is: '+ str(mofr.metrics.lift(df[train_mask][col_target], df[train_mask]['XGB_SCORE'])))\nprint('The gini on the train set is: '+ str(mofr.metrics.gini(df[train_mask][col_target], df[train_mask]['XGB_SCORE'])))\nprint('The accuracy on the train set is: '+ str(mofr.metrics.accuracy_score(df[train_mask][col_target], df[train_mask]['XGB_SCORE'].apply(lambda x: int(x>0.5)))))\nprint('\\n')\nprint('The Lift on the valid set is: '+ str(mofr.metrics.lift(df[valid_mask][col_target], df[valid_mask]['XGB_SCORE'])))\nprint('The gini on the valid set is: '+ str(mofr.metrics.gini(df[valid_mask][col_target], df[valid_mask]['XGB_SCORE'])))\nprint('The accuracy on the valid set is: '+ str(mofr.metrics.accuracy_score(df[valid_mask][col_target], df[valid_mask]['XGB_SCORE'].apply(lambda x: int(x>0.5)))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mofr.basic_evaluators.ROCCurve import ROCCurveEvaluator\ndf['one']=1\n\nrce=ROCCurveEvaluator()\nrce.d(df[valid_mask]).t([(col_target,'one')]).s(['XGB_SCORE'])\nrce.get_graph()\n\ndel df['one']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_idx = xgb_model.feature_importances_.argsort()\norder_ = []\nfor i in sorted_idx:\n  order_.append(col_preds[i])\nplt.figure(figsize=(10, 10))\nfig = plt.barh(order_, xgb_model.feature_importances_[sorted_idx])\nplt.xlabel(\"Xgboost Feature Importance\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# results=[]\n# for col in col_preds:\n#     results.append((col, np.abs(mofr.metrics.gini(df[valid_mask][col_target], df[valid_mask][col]))))\n  \n# pd.DataFrame(results, columns=['Predictor', 'GINI']).sort_values(by='GINI', ascending=False)[0:30]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the model","metadata":{}},{"cell_type":"code","source":"import pickle\nfile_name = \"hm_xgb_model.pkl\"\n\n# save\npickle.dump(xgb_model, open(file_name, \"wb\"))\n\n# # load\n# #xgb_model= pickle.load(open(file_name, \"rb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nfile_name = \"hm_encoder.pkl\"\n\n# save\npickle.dump(encoder, open(file_name, \"wb\"))\n\n# # load\n# #encoder = pickle.load(open(file_name, \"rb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional checks","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Categorical encoding check","metadata":{}},{"cell_type":"markdown","source":"## SHAP values","metadata":{}},{"cell_type":"code","source":"import shap  # package used to calculate Shap values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_to_show = 1\ndata_for_prediction = df[train_mask][col_preds].iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(xgb_model)\n\n# Calculate Shap values\nshap_values = explainer.shap_values(data_for_prediction_array)\nshap.initjs()\nshap.force_plot(explainer.expected_value, shap_values, data_for_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shap_values = explainer.shap_values(df[train_mask][col_preds])\n# shap.summary_plot(shap_values, df[train_mask][col_preds])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Future predictions part","metadata":{}},{"cell_type":"markdown","source":"Simple article preselection approach was chosen-> top 1000 articles by average XGB_SCORE ","metadata":{}},{"cell_type":"code","source":"del df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pickle\n# file_name1= \"hm_xgb_model.pkl\"\n# file_name2= \"hm_encoder.pkl\"\n\n# # load\n# xgb_model= pickle.load(open(file_name1, \"rb\"))\n# encoder= pickle.load(open(file_name2, \"rb\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles=pd.read_csv('/kaggle/input/hm-model-build-base/articles_predictions.csv')\ncustomers=pd.read_csv('/kaggle/input/hm-model-build-base/customers_prediction.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del customers['Unnamed: 0']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"customers['CUSTOMER_ID10']=customers['CUSTOMER_ID'].apply(lambda x: x[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"articles['ARTICLE_ID6']=articles['ARTICLE_ID'].apply(lambda x: int(str(x)[0:6]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Scoring customers in batches to produce submission file\nFor each of the 1000 suggested items and for each customer, then ordering and picking top 12","metadata":{"execution":{"iopub.status.busy":"2022-11-06T18:55:13.828054Z","iopub.execute_input":"2022-11-06T18:55:13.828620Z","iopub.status.idle":"2022-11-06T18:55:13.834468Z","shell.execute_reply.started":"2022-11-06T18:55:13.828574Z","shell.execute_reply":"2022-11-06T18:55:13.833557Z"}}},{"cell_type":"code","source":"submission=pd.DataFrame()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_chunk(chunk):\n    chunk=chunk.rename(columns={'CUSTOMER_ID':'CUSTOMER_ID10'}).drop_duplicates()\n    chunk.drop_duplicates(subset=['CUSTOMER_ID10', 'ARTICLE_ID'], inplace=True)\n    chunk=chunk.merge(articles, how='left', on='ARTICLE_ID')\n    chunk=chunk.merge(customers, how='left', left_on='CUSTOMER_ID10', right_on='CUSTOMER_ID10')\n    chunk = pd.concat([chunk, encoder.transform(chunk[cat_preds]).add_prefix(\"BAYES_\")], axis=1)\n    \n    chunk['XGB_SCORE']=xgb_model.predict_proba(chunk[xgb_model.feature_names_in_])[:, 1]\n    chunk['ARTICLE_ID']=chunk['ARTICLE_ID'].apply(str).apply(lambda x: x.zfill(10))\n    a=chunk[['CUSTOMER_ID', 'ARTICLE_ID', 'XGB_SCORE']].groupby('CUSTOMER_ID').apply(lambda x : x.sort_values(by = 'XGB_SCORE', ascending = False).head(12).reset_index(drop = True)).reset_index(drop = True)\n    b=pd.DataFrame(a.groupby('CUSTOMER_ID')['ARTICLE_ID'].apply(list).apply(' '.join)).reset_index(drop=False).rename(columns={'ARTICLE_ID':'PREDICTION'})\n    return b","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n=0\nchunksize = 10 ** 6\nwith pd.read_csv('/kaggle/input/suggested-items/model_suggested_items.csv', chunksize=chunksize) as reader:\n    for chunk in reader:\n        print(f'{n}: {round(n/3.94,2)} % done')\n        submission=pd.concat([submission,process_chunk(chunk)])\n        n+=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.drop_duplicates(subset='CUSTOMER_ID',keep='first', inplace=True, ignore_index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}